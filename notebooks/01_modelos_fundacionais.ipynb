{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Modelos Fundacionais\n",
    "\n",
    "Modelos de linguagem (LLMs) são redes neurais treinadas em grandes volumes de texto que aprenderam a gerar e compreender linguagem natural. Na prática, interagimos com eles por meio de **chat models**, que recebem mensagens e retornam respostas.\n",
    "\n",
    "O LangChain oferece uma interface unificada para trabalhar com modelos de diferentes provedores (OpenAI, Anthropic, Google, etc.) sem precisar mudar a estrutura do código. Isso é feito por meio da funcao `init_chat_model`, que inicializa qualquer modelo de chat a partir do nome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c2d3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4",
   "metadata": {},
   "source": [
    "## Inicializando um modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e2f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(model=\"gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "A funcao `init_chat_model` identifica automaticamente o provedor com base no nome do modelo. No caso de `gpt-4.1-nano`, ele sabe que pertence a OpenAI.\n",
    "\n",
    "Para enviar uma mensagem ao modelo, usamos o metodo `.invoke()`, que recebe um texto (ou uma lista de mensagens) e retorna um objeto de resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a2b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta = model.invoke(\"Qual o maior estado do Brasil em extensao territorial?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b3c4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O maior estado do Brasil em extensão territorial é o Amazonas.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 18, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_336de151a4', 'id': 'chatcmpl-DCtAXLfZqh9YSRze6PlQSVVDeWsy6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c914e-a864-7dd0-9482-a59230870a5e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 18, 'output_tokens': 12, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "O objeto retornado e do tipo `AIMessage`. Ele contem o texto da resposta em `.content`, alem de metadados sobre a chamada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2d3e4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O maior estado do Brasil em extensão territorial é o Amazonas.\n"
     ]
    }
   ],
   "source": [
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3f4a5",
   "metadata": {},
   "source": [
    "## Metadados da resposta\n",
    "\n",
    "Cada chamada ao modelo retorna metadados uteis, como o modelo usado, a quantidade de tokens consumidos e o motivo pelo qual a geracao parou. Essas informacoes sao importantes para monitorar custos e entender o comportamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2f3a4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'finish_reason': 'stop',\n",
      " 'id': 'chatcmpl-DCtAXLfZqh9YSRze6PlQSVVDeWsy6',\n",
      " 'logprobs': None,\n",
      " 'model_name': 'gpt-4.1-nano-2025-04-14',\n",
      " 'model_provider': 'openai',\n",
      " 'service_tier': 'default',\n",
      " 'system_fingerprint': 'fp_336de151a4',\n",
      " 'token_usage': {'completion_tokens': 12,\n",
      "                 'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
      "                                               'audio_tokens': 0,\n",
      "                                               'reasoning_tokens': 0,\n",
      "                                               'rejected_prediction_tokens': 0},\n",
      "                 'prompt_tokens': 18,\n",
      "                 'prompt_tokens_details': {'audio_tokens': 0,\n",
      "                                           'cached_tokens': 0},\n",
      "                 'total_tokens': 30}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(resposta.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5",
   "metadata": {},
   "source": [
    "## Parametros do modelo\n",
    "\n",
    "Ao inicializar o modelo, podemos passar parametros adicionais que alteram seu comportamento. O mais comum e a **temperature**, que controla a aleatoriedade das respostas:\n",
    "\n",
    "- `temperature=0` gera respostas mais deterministicas e previsveis\n",
    "- `temperature=1` ou acima gera respostas mais criativas e variadas\n",
    "\n",
    "Para tarefas objetivas (extracao de dados, classificacao), prefira temperatura baixa. Para tarefas criativas (geracao de texto, brainstorming), use temperatura mais alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro! Uma curiosidade interessante sobre Brasília é que ela foi planejada e construída em apenas cerca de três anos, de 1956 a 1960, para ser a nova capital do Brasil. O projeto foi elaborado pelo arquiteto Oscar Niemeyer e pelo urbanista Lúcio Costa, e a cidade foi inaugurada oficialmente em 21 de abril de 1960. Brasília é considerada uma das maiores obras de arquitetura moderna do mundo e foi reconhecida como Patrimônio Mundial pela UNESCO em 1987 devido ao seu planejamento urbano inovador e arquitetura única.\n"
     ]
    }
   ],
   "source": [
    "model = init_chat_model(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "resposta = model.invoke(\"Me conta uma curiosidade sobre Brasilia.\")\n",
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c4d5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro! Uma curiosidade interessante sobre Brasília é que ela foi diferente de muitas capitais, pois foi planejada e construída do zero — sua construção começou em 1956, e altura de 1960 já servia como nova capital do Brasil. Francisco Netto Stein criou o projeto urbanístico, que inclui formidáveis abertas e discard útil para refletir progresso, modernidade e unziunidade composta.tar foto!\n"
     ]
    }
   ],
   "source": [
    "model = init_chat_model(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "resposta = model.invoke(\"Me conta uma curiosidade sobre Brasilia.\")\n",
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## Trocando de provedor\n",
    "\n",
    "Uma das grandes vantagens do LangChain e a **intercambiabilidade de provedores**. O mesmo codigo funciona com OpenAI, Anthropic, Google e dezenas de outros provedores. Basta mudar o nome do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e4f5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O maior estado do Brasil em extensão territorial é o **Amazonas**, com aproximadamente 1.570.745,68 km².\n",
      "\n",
      "O Amazonas ocupa cerca de 18,4% de todo o território brasileiro e é maior que muitos países. Para ter uma ideia da dimensão, ele é maior que países como Peru, Colômbia e até mesmo maior que a soma de vários países europeus.\n",
      "\n",
      "Em segundo lugar vem o Pará, com cerca de 1.247.689 km², seguido pelo Mato Grosso em terceiro.\n"
     ]
    }
   ],
   "source": [
    "model = init_chat_model(model=\"claude-sonnet-4-20250514\")\n",
    "\n",
    "resposta = model.invoke(\"Qual o maior estado do Brasil em extensao territorial?\")\n",
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4a5b6",
   "metadata": {},
   "source": [
    "Observe que nao mudamos nada na estrutura do codigo. Apenas trocamos o nome do modelo de `gpt-4.1-nano` para `claude-sonnet-4-20250514`, e o LangChain cuidou de usar o provedor correto (Anthropic) automaticamente.\n",
    "\n",
    "A lista completa de provedores e modelos suportados esta na documentacao: https://docs.langchain.com/oss/python/integrations/chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4b5c6",
   "metadata": {},
   "source": [
    "## Modelos vs. Agentes\n",
    "\n",
    "Ate agora usamos o modelo diretamente com `init_chat_model`. Isso e util para chamadas simples, mas no mundo real queremos mais: ferramentas, memoria, system prompts, output estruturado.\n",
    "\n",
    "Para isso, o LangChain oferece a funcao `create_agent`, que cria um **agente** a partir de um modelo. Um agente e um sistema que pode:\n",
    "\n",
    "- Receber instrucoes via system prompt\n",
    "- Usar ferramentas (tools) para executar acoes\n",
    "- Manter memoria entre interacoes\n",
    "- Decidir autonomamente quando e quais ferramentas usar\n",
    "\n",
    "Na pratica, o agente usa o modelo como seu \"cerebro\", mas adiciona capacidades extras em torno dele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4b5c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agente = create_agent(model=\"gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "A interface do agente e diferente do modelo. Em vez de receber uma string diretamente, o agente espera um dicionario com a chave `messages`, contendo uma lista de objetos de mensagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d5e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "pergunta = HumanMessage(content=\"Quem projetou Brasilia?\")\n",
    "\n",
    "resposta = agente.invoke(\n",
    "    {\"messages\": [pergunta]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Quem projetou Brasilia?', additional_kwargs={}, response_metadata={}, id='4928b2be-1647-4e5a-833c-cf5c18395e3d'),\n",
      "              AIMessage(content='Brasília foi projetada pelo arquiteto brasileiro Lúcio Costa, que elaborou o plano piloto da cidade, e pelo arquiteto e urbanista Oscar Niemeyer, responsável pelos principais edifícios e monumentos. A concepção e o planejamento da cidade também envolveram o esforço de uma equipe de especialistas e engenheiros, mas Lúcio Costa e Oscar Niemeyer são os principais nomes associados ao projeto de Brasília.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 13, 'total_tokens': 99, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_336de151a4', 'id': 'chatcmpl-DCtAgtw7jy8YoIDDOXQF20Ma34hF2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c914e-caea-7232-92cf-843e43c9a883-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 13, 'output_tokens': 86, 'total_tokens': 99, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "pprint(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f5a6b7",
   "metadata": {},
   "source": [
    "A resposta do agente e um dicionario contendo a chave `messages`, que e uma lista com todas as mensagens da conversa, tanto as enviadas quanto as recebidas. A ultima mensagem e sempre a resposta do agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4a5b6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brasília foi projetada pelo arquiteto brasileiro Lúcio Costa, que elaborou o plano piloto da cidade, e pelo arquiteto e urbanista Oscar Niemeyer, responsável pelos principais edifícios e monumentos. A concepção e o planejamento da cidade também envolveram o esforço de uma equipe de especialistas e engenheiros, mas Lúcio Costa e Oscar Niemeyer são os principais nomes associados ao projeto de Brasília.\n"
     ]
    }
   ],
   "source": [
    "print(resposta[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6c7d8",
   "metadata": {},
   "source": [
    "## Historico manual de mensagens\n",
    "\n",
    "Podemos simular uma conversa passando manualmente uma lista de mensagens alternando entre `HumanMessage` (usuario) e `AIMessage` (modelo). Isso permite dar contexto ao agente sobre o que ja foi conversado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c6d7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brasília foi inaugurada em 21 de abril de 1960.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AIMessage\n",
    "\n",
    "resposta = agente.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"Quem projetou Brasilia?\"),\n",
    "        AIMessage(content=\"Brasilia foi projetada pelo urbanista Lucio Costa, com edificios desenhados por Oscar Niemeyer.\"),\n",
    "        HumanMessage(content=\"Em que ano ela foi inaugurada?\"),\n",
    "    ]}\n",
    ")\n",
    "\n",
    "print(resposta[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f8",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "Em aplicacoes reais, esperamos que a resposta apareca token a token, como acontece no ChatGPT. Isso e chamado de **streaming** e melhora a experiencia do usuario, pois ele comeca a ler a resposta enquanto ela ainda esta sendo gerada.\n",
    "\n",
    "No LangChain, usamos o metodo `.stream()` do agente com `stream_mode=\"messages\"`. Cada iteracao retorna um token e seus metadados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5e6f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alberto Santos Dumont, conhecido como o \"Pai da Aviação\", nasceu em 20 de julho de 1873, em Palmira, atualmente município de Santos Dumont, em Minas Gerais. Desde cedo, demonstrou grande interesse por invenções e pelo avanço tecnológico, dedicando-se ao estudo do funcionamento de máquinas e ao desenvolvimento de projetos aeronáuticos. Sua paixão o levou a experimentar diversos protótipos de balões e dirigíveis, culminando na criação de veículos capazes de voar de forma controlada, um marco importante na história da aviação.\n",
      "\n",
      "Nos anos 1906 e 1907, Santos Dumont realizou feitos que conquistaram reconhecimento mundial, incluindo o voo do 14-bis, na então França. Em 23 de outubro de 1906, na manhã de domingo, ele realizou o primeiro voo registrado oficialmente com um aparelho mais pesado que o ar, percorrendo aproximadamente 60 metros no Campo de Bagatelle, em Paris. Esse voo é considerado por muitos como o primeiro a ocorrer de forma realmente controlada e sustentável, marcando um avanço fundamental na história do transporte aéreo.\n",
      "\n",
      "Santos Dumont é também valorizado por seu espírito inovador e seu caráter pioneiro. Ele trabalhou incessantemente para aprimorar seus projetos, enfrentando desafios técnicos e sociais, além de promover a aviação como uma atividade acessível. Sua dedicação e conquistas ajudaram a consolidar a aviação como ciência e indústria, e seu legado permanece como símbolo de inovação e coragem no céu. Ele faleceu em Paris em 1932, deixando uma eterna inspiração para inventores e entusiastas do voo ao redor do mundo."
     ]
    }
   ],
   "source": [
    "for token, metadata in agente.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Me fale sobre a historia de Santos Dumont em 3 paragrafos.\")]},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    if token.content:\n",
    "        print(token.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
